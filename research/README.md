# ğŸ“š RevisÃ£o SistemÃ¡tica da Literatura - CCW Research

## ğŸ¯ VisÃ£o Geral

Sistema modular para revisÃ£o sistemÃ¡tica da literatura em educaÃ§Ã£o matemÃ¡tica com tÃ©cnicas computacionais, seguindo protocolo PRISMA.

**Status atual**: âœ… Pipeline completo funcionando | ğŸ§ª Testes validados (100% pass rate) | ğŸ“Š VisualizaÃ§Ãµes PRISMA corretas

---

## âš¡ Quick Start

```bash
# 1. Instalar dependÃªncias
cd c:\dev\ccw
pip install -r research/requirements.txt

# 2. Configurar ambiente (opcional)
cp research/.env.example research/.env
# Editar .env com credenciais de APIs se necessÃ¡rio

# 3. Executar pipeline completo
python -m research.src.cli run-pipeline
python -m research.src.cli export

# 4. Ver resultados
# Os arquivos sÃ£o gerados em research/exports/
```

---

## ğŸ—ï¸ Arquitetura do Sistema

```text
research/
â”œâ”€â”€ src/                          # CÃ³digo fonte modular
â”‚   â”œâ”€â”€ config.py                 # ConfiguraÃ§Ã£o centralizada
â”‚   â”œâ”€â”€ cli.py                    # CLI principal
â”‚   â”œâ”€â”€ database/                 # Gerenciamento SQLite
â”‚   â”‚   â”œâ”€â”€ manager.py            # Interface do banco
â”‚   â”‚   â””â”€â”€ schema.py             # Schema + migrations
â”‚   â”œâ”€â”€ ingestion/                # Coleta de dados
â”‚   â”‚   â”œâ”€â”€ semantic_scholar.py  # Semantic Scholar API
â”‚   â”‚   â”œâ”€â”€ openalex.py           # OpenAlex API
â”‚   â”‚   â”œâ”€â”€ crossref.py           # Crossref API
â”‚   â”‚   â””â”€â”€ core.py               # CORE API (instÃ¡vel)
â”‚   â”œâ”€â”€ processing/               # Processamento de dados
â”‚   â”‚   â”œâ”€â”€ dedup.py              # DeduplicaÃ§Ã£o DOI+TF-IDF
â”‚   â”‚   â”œâ”€â”€ scoring.py            # Score de relevÃ¢ncia
â”‚   â”‚   â”œâ”€â”€ selection.py          # SeleÃ§Ã£o PRISMA
â”‚   â”‚   â””â”€â”€ language_utils.py     # DetecÃ§Ã£o de idioma
â”‚   â”œâ”€â”€ analysis/                 # AnÃ¡lise e visualizaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ visualizations.py     # GrÃ¡ficos PRISMA
â”‚   â”‚   â””â”€â”€ reports.py            # RelatÃ³rios HTML
â”‚   â”œâ”€â”€ exports/                  # ExportaÃ§Ã£o de dados
â”‚   â”‚   â””â”€â”€ excel.py              # Excel + CSV + JSON
â”‚   â””â”€â”€ pipeline/                 # OrquestraÃ§Ã£o
â”‚       â””â”€â”€ run.py                # Pipeline completo
â”œâ”€â”€ tests/                        # Testes automatizados
â”‚   â”œâ”€â”€ test_prisma_stages.py     # âœ… ValidaÃ§Ã£o PRISMA
â”‚   â”œâ”€â”€ test_complete_pipeline.py # Suite completa
â”‚   â””â”€â”€ test_performance_benchmark.py
â”œâ”€â”€ exports/                      # SaÃ­das geradas
â”‚   â”œâ”€â”€ summary_report.html       # RelatÃ³rio resumido
â”‚   â”œâ”€â”€ papers_report.html        # Papers incluÃ­dos
â”‚   â”œâ”€â”€ gap_analysis.html         # AnÃ¡lise de lacunas
â”‚   â”œâ”€â”€ analysis/                 # Dados estruturados
â”‚   â”œâ”€â”€ visualizations/           # GrÃ¡ficos PNG
â”‚   â””â”€â”€ reports/                  # RelatÃ³rios completos
â”œâ”€â”€ cache/                        # Cache de APIs
â”œâ”€â”€ logs/                         # Logs de execuÃ§Ã£o
â””â”€â”€ systematic_review.db          # Banco SQLite principal
```

---

## ğŸ” Metodologia PRISMA

### Bases de Dados Integradas

| API | Cobertura | Status | Taxa de Sucesso |
|-----|-----------|--------|-----------------|
| **Semantic Scholar** | CS + multidisciplinar | âœ… EstÃ¡vel | >95% |
| **OpenAlex** | 250M+ works abertos | âœ… EstÃ¡vel | >95% |
| **Crossref** | Metadados DOI | âœ… EstÃ¡vel | >95% |
| **CORE** | Open access | âš ï¸ InstÃ¡vel | ~70% |

### EstratÃ©gia de Busca

**108 queries bilÃ­ngues estruturadas** (72 inglÃªs + 36 portuguÃªs) combinando:

**Termos PrimÃ¡rios** (6 termos - domÃ­nio educacional):

- "mathematics education", "math learning", "mathematics teaching"
- "educaÃ§Ã£o matemÃ¡tica", "aprendizagem matemÃ¡tica", "ensino de matemÃ¡tica"

**Termos SecundÃ¡rios** (22 termos - tÃ©cnicas computacionais):

- Machine learning, artificial intelligence, deep learning, neural networks
- Adaptive learning, personalized learning, intelligent tutoring systems
- Learning analytics, educational data mining, predictive analytics
- Student modeling, competency identification, automated assessment
- E mais 10 termos relacionados

### CritÃ©rios de SeleÃ§Ã£o

**âœ… InclusÃ£o**:

- Artigos peer-reviewed (2015-2025)
- Foco em tÃ©cnicas computacionais + educaÃ§Ã£o matemÃ¡tica
- Metodologia e evidÃªncias empÃ­ricas claras
- Idiomas: inglÃªs ou portuguÃªs

**âŒ ExclusÃ£o**:

- Metodologia insuficiente (abstract <50 palavras)
- Foco nÃ£o-educacional (biologia, fÃ­sica sem contexto educacional)
- ConteÃºdo nÃ£o-cientÃ­fico (editoriais, comentÃ¡rios)
- Baixa relevÃ¢ncia (score <4.0)

### Fluxo PRISMA

O pipeline segue as fases padrÃ£o: IdentificaÃ§Ã£o â†’ DeduplicaÃ§Ã£o â†’ Triagem â†’
Elegibilidade â†’ InclusÃ£o.

**NÃºmeros atuais (25/11/2025)**:

- **IdentificaÃ§Ã£o**: 9.431 registros coletados
- **Duplicatas Removidas**: 2.494 (26,4%)
- **Screening**: 6.937 estudos Ãºnicos avaliados
- **Elegibilidade**: 1.883 avaliados em profundidade (excluÃ­dos na elegibilidade: 1.866 / 99,1%)
- **IncluÃ­dos**: 17 estudos (pontuaÃ§Ã£o de relevÃ¢ncia â‰¥ 4,0)

Todos os contadores oficiais sÃ£o derivados em tempo de execuÃ§Ã£o a partir
do banco de dados canÃ´nico `research/systematic_review.db`.

Para obter os nÃºmeros atualizados execute:

```bash
# Mostrar contagens PRISMA diretamente do banco
python -m research.src.cli stats

# Ou consultar via SQL:
sqlite3 research/systematic_review.db "SELECT COUNT(*) FROM papers;"
sqlite3 research/systematic_review.db "SELECT COUNT(*) FROM papers WHERE selection_stage='included';"
```

Arquivos de exportaÃ§Ã£o e relatÃ³rios em `research/exports/` contÃªm as versÃµes
renderizadas (CSV/HTML/PNG) usadas para publicaÃ§Ãµes e para o README. Sempre
consulte esses artefatos para nÃºmeros fixos gerados em uma execuÃ§Ã£o especÃ­fica.

---

## ğŸš€ Como Usar

### CLI Completo

```bash
# Executar pipeline completo
python -m research.src.cli run-pipeline
  --apis semantic_scholar openalex crossref core  # APIs especÃ­ficas
  --min-score 4.5                            # Score mÃ­nimo customizado
  --limit-per-query 100                      # Limite por query

# Ver estatÃ­sticas
python -m research.src.cli stats

# Mostrar amostra de papers
python -m research.src.cli show

# Importar dados externos
python -m research.src.cli import-csv dados.csv

# Exportar com relatÃ³rios e visualizaÃ§Ãµes
python -m research.src.cli export -o research/exports/

# Exportar incluindo extraÃ§Ã£o de texto completo dos PDFs
python -m research.src.cli export --fetch-fulltext

# Extrair apenas artigos sem full_text no banco
python -m research.src.cli export --fetch-fulltext --only-missing

# Normalizar estÃ¡gios PRISMA (se necessÃ¡rio)
python -m research.src.cli normalize-prisma
```

### UtilitÃ¡rios de Auditoria (Centralizados no CLI)

Use estes comandos em vez dos scripts avulsos em `tools/` e `research/scripts/`:

```bash
# Auditoria cruzada DB â†’ Exports â†’ PTC (gera JSON/MD em research/logs)
python -m research.src.cli audit

# Valida DB â†” CSV â†” summary.json (salva JSON em research/logs)
python -m research.src.cli validate-exports

# Checagem ampla de exports, incluindo parsing dos relatÃ³rios HTML
python -m research.src.cli check-exports

# VerificaÃ§Ã£o de duplicatas/ausÃªncias/irrelevÃ¢ncia no CSV (gera CSV de relatÃ³rio)
python -m research.src.cli verify-papers --csv research/exports/analysis/papers.csv

# Regenera summary.json a partir do DB canÃ´nico
python -m research.src.cli regenerate-summary

# Diagnostica por que um paper foi incluÃ­do (busca por tÃ­tulo)
python -m research.src.cli diagnose-included --title "parte do tÃ­tulo"
```

ObservaÃ§Ã£o: os scripts antigos `tools/*.py` e `research/scripts/*.py` estÃ£o
obsoletos e serÃ£o removidos em breve. Todos os fluxos foram centralizados no CLI.

### Uso ProgramÃ¡tico

```python
from research.src.pipeline.run import SystematicReviewPipeline
from research.src.config import load_config

config = load_config()
pipeline = SystematicReviewPipeline(config)

# Pipeline completo
results = pipeline.run_full_pipeline(
    export=True,
    min_relevance_score=4.0
)

# Ou por etapas
pipeline.generate_search_queries()
pipeline.collect_data(apis=["semantic_scholar", "openalex"])
pipeline.process_data()
pipeline.apply_selection_criteria(min_relevance_score=4.5)
files = pipeline.export_results()
```

---

## ğŸ“Š Outputs Gerados

### Arquivos de ExportaÃ§Ã£o

**Em `research/exports/`** (arquivos fixos, data no conteÃºdo):

1. **summary_report.html**: RelatÃ³rio resumido com estatÃ­sticas gerais
2. **papers_report_included.html**: Lista de papers incluÃ­dos com detalhes
3. **gap_analysis.html**: AnÃ¡lise de lacunas de pesquisa
4. **index.html**: Ãndice navegÃ¡vel de todos os relatÃ³rios

**Em `research/exports/analysis/`**:

- `papers.xlsx`: Dados completos em Excel
- `papers.csv`: Dados em CSV
- `papers.json`: Dados em JSON

**Em `research/exports/visualizations/`**:

- `prisma_flow.png`: Diagrama de fluxo PRISMA
- `selection_funnel.png`: Funil de seleÃ§Ã£o
- `papers_by_year.png`: DistribuiÃ§Ã£o temporal
- `techniques_distribution.png`: TÃ©cnicas computacionais
- `database_coverage.png`: Cobertura por API
- `relevance_distribution.png`: DistribuiÃ§Ã£o de relevÃ¢ncia

### Dados nos Papers IncluÃ­dos

Cada paper incluÃ­do registra:

- **CritÃ©rios atendidos**: year_range, language, math_focus, computational_techniques
- **PontuaÃ§Ã£o de relevÃ¢ncia**: 0â€“10 (incluÃ­dos â‰¥ 4,0)
- **Motivo de inclusÃ£o**: Lista de critÃ©rios que qualificaram o paper
- **Fonte**: API de origem (semantic_scholar, openalex, crossref, core)
- **Metadados completos**: tÃ­tulo, abstract, autores, ano, DOI, etc.

---

## ğŸ“„ ExtraÃ§Ã£o de Texto Completo

### Funcionalidade Integrada

A partir da versÃ£o atual, a extraÃ§Ã£o de texto completo dos PDFs foi **integrada ao comando `export`**, eliminando a necessidade de executar comandos separados. O sistema agora oferece:

**Uso**:

```bash
# Exportar + extrair texto completo de todos os papers
python -m research.src.cli export --fetch-fulltext

# Processar apenas papers sem texto jÃ¡ extraÃ­do (incremental)
python -m research.src.cli export --fetch-fulltext --only-missing
```

### EstratÃ©gias de ExtraÃ§Ã£o

O sistema utiliza mÃºltiplas estratÃ©gias para maximizar a taxa de sucesso:

1. **Resolvedores de PDF**:
   - IEEE Stamp URLs (papers do IEEE Xplore)
   - Unpaywall API (open access papers)
   - Crossref metadata links
   - CORE API (repositÃ³rios acadÃªmicos)
   - HTML scraping para publishers open access

2. **Fallbacks Inteligentes**:
   - Tentativa de mÃºltiplos protocolos (HTTPS â†’ HTTP)
   - RotaÃ§Ã£o de User-Agents
   - Cache de resultados para evitar reprocessamento

3. **ValidaÃ§Ã£o Robusta**:
   - VerificaÃ§Ã£o HEAD antes do download completo
   - DetecÃ§Ã£o de content-type (PDF vs HTML)
   - ExtraÃ§Ã£o de texto com PyPDF2 + pdfplumber

### InformaÃ§Ãµes nos RelatÃ³rios

Os relatÃ³rios HTML gerados agora incluem:

**Em `summary_report.html`**:
- Card de cobertura com percentual de extraÃ§Ã£o
- Total de papers extraÃ­dos vs falhas
- Top 5 causas de falha mais frequentes

**Em `papers_report_included.html`**:
- Badge de status (âœ… ExtraÃ­do / âŒ NÃ£o extraÃ­do)
- Tamanho do texto extraÃ­do (em KB)
- Palavras-chave detectadas automaticamente
- Motivos de falha quando aplicÃ¡vel

### Taxa de Sucesso Atual

**Cobertura**: ~41% (7/17 papers incluÃ­dos)

**Principais Causas de Falha**:
- `connection_exhausted`: Timeout apÃ³s mÃºltiplas tentativas
- `head_error`: Erro na verificaÃ§Ã£o HEAD do URL
- `ieee_no_fallback_link`: IEEE sem link de fallback disponÃ­vel
- `html_no_pdf_link`: PÃ¡gina HTML sem link direto para PDF

### Cache e PersistÃªncia

- **Cache JSON**: `research/exports/full_texts_cache.json`
- **Banco de dados**: Campo `full_text` na tabela `papers`
- **Incremental**: Flag `--only-missing` processa apenas novos papers

---

## ğŸ§ª Testes Automatizados

### Executar Testes

```bash
# Todos os testes
cd research && pytest

# Testes PRISMA especÃ­ficos
pytest research/tests/test_prisma_stages.py -v

# Com cobertura
pytest --cov=research.src --cov-report=html
```

### Suite de Testes

**âœ… test_prisma_stages.py** (9 testes, 100% pass):

- CritÃ©rios de inclusÃ£o/exclusÃ£o
- Fases PRISMA (screening, eligibility, inclusion)
- ConsistÃªncia de estatÃ­sticas
- Registro de motivos de exclusÃ£o/inclusÃ£o

**âœ… test_complete_pipeline.py**:

- IntegraÃ§Ã£o completa do pipeline
- ValidaÃ§Ã£o de APIs e coleta
- Processamento e deduplicaÃ§Ã£o
- SeleÃ§Ã£o PRISMA e exportaÃ§Ã£o

**âœ… test_performance_benchmark.py**:

- MÃ©tricas de performance
- Cache hit rate
- Tempo de execuÃ§Ã£o por fase

---

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (.env)

```bash
# APIs (opcionais - funcionam sem chaves)
SEMANTIC_SCHOLAR_API_KEY=your_key
CORE_API_KEY=your_key
USER_EMAIL=your_email@domain.com

# Rate limits (segundos entre requests)
SEMANTIC_SCHOLAR_RATE_DELAY=4.0
OPENALEX_RATE_DELAY=6.0
CROSSREF_RATE_DELAY=4.0

# CritÃ©rios de revisÃ£o
REVIEW_YEAR_MIN=2015
REVIEW_YEAR_MAX=2025
REVIEW_LANGUAGES=en,pt
REVIEW_RELEVANCE_THRESHOLD=4.0  # limiar de relevÃ¢ncia
```

### Personalizar Termos de Busca

Edite `research/src/config/search_terms.py`:

```python
# Adicionar novos termos
COMPUTATIONAL_TECHNIQUES_EN.append("new_technique")
EDUCATIONAL_CONTEXTS_PT.append("novo_contexto")

# Sistema gera automaticamente todas as combinaÃ§Ãµes
```

---

## ğŸ”§ Funcionalidades TÃ©cnicas

### Sistema de Cache Inteligente

- Cache local por query em JSON
- Speedup atÃ© 22x em execuÃ§Ãµes repetidas
- Evita sobrecarga nas APIs
- Armazenamento eficiente por fonte

### DeduplicaÃ§Ã£o AvanÃ§ada

**EstratÃ©gia em 3 nÃ­veis**:

1. DOI/URL idÃªnticos (remoÃ§Ã£o direta)
2. Similaridade TF-IDF de tÃ­tulos (limiar 0,9)
3. PreservaÃ§Ã£o da melhor fonte (DOI > abstract completo)

### Scoring Multi-CritÃ©rio

**Score 0-10 baseado em**:

- TÃ©cnicas computacionais mencionadas
- Contexto educacional matemÃ¡tico
- Qualidade metodolÃ³gica
- MÃ©tricas de impacto (citaÃ§Ãµes, H-index)

### DetecÃ§Ã£o Robusta de Idioma

**EstratÃ©gia hÃ­brida**:

1. `langdetect` em tÃ­tulo + abstract + keywords
2. Fallback regex para portuguÃªs/inglÃªs
3. Cache de resultados para performance

### Logging Estruturado

**Ãšnico arquivo de log ativo**:

- `research/logs/ingestion.base.log`: Log consolidado de todas as operaÃ§Ãµes
- RotaÃ§Ã£o automÃ¡tica quando atinge 10MB
- 3 backups mantidos
- Formato: `timestamp | level | module | message`

---

## ğŸ› Troubleshooting

### Problemas Comuns

**Rate Limiting (HTTP 429)**:

```bash
# Aumentar delays no .env
SEMANTIC_SCHOLAR_RATE_DELAY=6.0
OPENALEX_RATE_DELAY=8.0
```

**Logs Detalhados**:

```bash
# Habilitar debug
export DEBUG=1
python -m research.src.cli run-pipeline
```

**Performance Lenta**:

- Usar cache em execuÃ§Ãµes subsequentes (automÃ¡tico)
- Reduzir nÃºmero de queries (`--limit-per-query 50`)
- Usar apenas APIs estÃ¡veis (`--apis semantic_scholar openalex`)

---

## ğŸ“ˆ MÃ©tricas de Qualidade

### Performance Atual

- **Taxa de sucesso das APIs**: >95% (exceto CORE ~70%)
- **Tempo de execuÃ§Ã£o**: 30-60 minutos (108 queries Ã— 4 APIs)
- **Taxa de deduplicaÃ§Ã£o**: ~40% (DOI+similaridade)
- **Taxa de inclusÃ£o final**: ~0,25% (16 de 6.516)
- **Cobertura temporal**: 2017-2026 (10 anos completos)
- **Cache hit rate**: ~63% (268 hits / 425 entradas)

### Qualidade dos Dados

- **Papers com abstract**: >85%
- **Papers com DOI**: >60%
- **Papers com ano vÃ¡lido**: >95%
- **Reprodutibilidade**: 100% via CLI + config

---

## ğŸ“ ContribuiÃ§Ã£o para o TCC

### EntregÃ¡veis Prontos

1. âœ… Base de dados estruturada (SQLite)
2. âœ… AnÃ¡lises estatÃ­sticas automatizadas
3. âœ… VisualizaÃ§Ãµes profissionais (PNG)
4. âœ… RelatÃ³rios HTML completos
5. âœ… Pipeline reprodutÃ­vel e auditÃ¡vel

### Metodologia CientÃ­fica

- âœ… Protocolo PRISMA completo
- âœ… TransparÃªncia total (cÃ³digo aberto)
- âœ… Reprodutibilidade garantida
- âœ… Auditabilidade via logs
- âœ… Rastreabilidade de cada paper

### Insights para o ProtÃ³tipo

**TÃ©cnicas Mais Utilizadas**:

- Machine learning para modelagem
- Learning analytics para personalizaÃ§Ã£o
- Sistemas adaptativos baseados em competÃªncias
- AvaliaÃ§Ã£o automatizada com feedback

**Lacunas Identificadas**:

- IntegraÃ§Ã£o de mÃºltiplas tÃ©cnicas
- Escalabilidade para grandes turmas
- AdaptaÃ§Ã£o cultural e pedagÃ³gica
- MÃ©tricas padronizadas de avaliaÃ§Ã£o

---

## ğŸ‘¥ CrÃ©ditos

**Autor**: Thales Ferreira
**TCC - CiÃªncia da ComputaÃ§Ã£o**  
**InstituiÃ§Ã£o**: IFC Videira  
**PerÃ­odo**: 2025-2026

### ğŸ“š ReferÃªncias

- [PRISMA Guidelines](http://www.prisma-statement.org/)
- [Semantic Scholar API](https://api.semanticscholar.org/)
- [OpenAlex API](https://docs.openalex.org/)
- [Crossref API](https://github.com/CrossRef/rest-api-doc)
- [CORE API](https://core.ac.uk/docs/)

---

*ğŸ“… Ãšltima atualizaÃ§Ã£o: Outubro 2025*  
*âœ… Status: Sistema funcionando | Pipeline validado | Testes 100% pass*
