# ğŸ” Auditoria de CoesÃ£o de Dados

**Data**: 16/11/2025 22:35  
**Objetivo**: Validar consistÃªncia entre banco de dados SQLite, exports CLI e documentaÃ§Ã£o  
**Status**: âš ï¸ **INCONSISTÃŠNCIAS CRÃTICAS ENCONTRADAS**

---

## ğŸ“Š Resumo Executivo

| Fonte | Identificados | Triagem | Elegibilidade | IncluÃ­dos | Status |
|-------|---------------|---------|---------------|-----------|--------|
| **Banco SQLite** | **6.516** | 6.516 | 1.835 | **16** | âœ… **CANÃ”NICO** |
| **CLI `stats`** | 6.516 | 4.665 | 1.835 | 16 | âœ… Correto |
| **Export HTML** | **9.356** | 6.516 | 1.851 | 16 | âŒ **INCORRETO** |
| **Docs (METODOLOGIA.md)** | 6.516 | 4.665 | 1.835 | 16 | âœ… Correto |
| **Docs (RESUMO.md)** | 6.516 | 4.665 | 1.835 | 16 | âœ… Correto |

### âš ï¸ InconsistÃªncias CrÃ­ticas

1. **Export HTML mostra 9.356 identificados** (linha 56 de `summary_report.html`)
   - Valor correto: **6.516**
   - DiscrepÃ¢ncia: +2.840 papers fantasmas
   - Causa: FunÃ§Ã£o `_compute_prisma_stats_from_df()` usando `dedup_stats.initial_count` ao invÃ©s de `len(df)`

2. **PRISMA flow mostra 2.594 duplicatas removidas**
   - Valor real no banco: **0 duplicatas marcadas**
   - Query: `SELECT COUNT(*) FROM papers WHERE exclusion_reason LIKE '%duplic%'` â†’ 0
   - Causa: CÃ³digo calculando diferenÃ§a fictÃ­cia (9356 - 6762 = 2594)

3. **Elegibilidade com valores inconsistentes**
   - HTML: 1.851 aprovados (linha 81)
   - Banco: 1.835 no estÃ¡gio `eligibility` + 16 `included` = 1.851 âœ…
   - CÃ¡lculo correto, mas nomenclatura confusa (deveria ser "Passaram para elegibilidade")

---

## ğŸ—„ï¸ Fonte CanÃ´nica: Banco SQLite

### Consulta Direta ao Banco

```bash
$ sqlite3 research/systematic_review.sqlite "SELECT COUNT(*) FROM papers"
6516

$ sqlite3 research/systematic_review.sqlite "SELECT selection_stage, COUNT(*) FROM papers GROUP BY selection_stage"
eligibility|1835
included|16
screening|4665
```

### MÃ©tricas Validadas (16/11/2025 22:30)

```
ğŸ“Š VALORES CANÃ”NICOS (Banco SQLite)
â”œâ”€ Total papers Ãºnicos: 6.516
â”œâ”€ Duplicatas marcadas: 0
â”œâ”€ Status:
â”‚  â”œâ”€ excluded: 6.500
â”‚  â””â”€ included: 16
â””â”€ EstÃ¡gios (selection_stage):
   â”œâ”€ screening: 4.665 (71,6% do total)
   â”œâ”€ eligibility: 1.835 (28,2% do total)
   â””â”€ included: 16 (0,25% do total)

âœ… INCLUÃDOS (16 estudos)
â”œâ”€ Score mÃ©dio: 4.20
â”œâ”€ Score mÃ­nimo: 4.0
â”œâ”€ Score mÃ¡ximo: 4.5
â””â”€ Anos: 2017-2025 (9 anos com dados)

âŒ EXCLUÃDOS (6.500 papers)
â”œâ”€ abstract_too_short: 2.720 (41,8%)
â”œâ”€ low_relevance_score: 1.835 (28,2%)
â”œâ”€ inclusion_criteria_not_met: 1.010 (15,5%)
â”œâ”€ no_methodology: 870 (13,4%)
â”œâ”€ non_research: 50 (0,8%)
â””â”€ off_topic: 15 (0,2%)
```

---

## ğŸ”§ CLI: Comando `stats`

### ExecuÃ§Ã£o em 16/11/2025 22:26

```bash
$ python -m research.src.cli stats

Total de papers: 6516

ğŸ“‹ Por estÃ¡gio de seleÃ§Ã£o:
  eligibility: 1835
  Included: 16
  screening: 4665

ğŸ—ƒï¸ Por base de dados:
  core: 126 (1,9%)
  crossref: 2815 (43,2%)
  openalex: 1793 (27,5%)
  semantic_scholar: 1782 (27,3%)

ğŸ“… Por ano (Ãºltimos 10):
  2017-2025: 6.516 papers
  (distribuiÃ§Ã£o detalhada no relatÃ³rio)

ğŸ’¾ Cache: 278 entradas, 0 hits
```

**âœ… Status**: CLI estÃ¡ **CORRETO** - reflete exatamente o banco SQLite

---

## ğŸ“¤ Exports: Comando `export`

### Arquivos Gerados

```
research/exports/analysis/
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ revisao_sistematica.xlsx    âœ… 6.516 linhas (correto)
â”‚   â”œâ”€â”€ papers.xlsx                 âœ… 6.516 linhas (correto)
â”‚   â”œâ”€â”€ papers.csv                  âœ… 6.516 linhas (correto)
â”‚   â””â”€â”€ papers.json                 âœ… 6.516 registros (correto)
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ summary_report.html         âŒ Mostra "9356 Total de Papers" (INCORRETO)
â”‚   â”œâ”€â”€ papers_report_included.html âœ… 16 papers (correto)
â”‚   â””â”€â”€ gap_analysis.html           âœ… Baseado nos 16 (correto)
â”‚
â””â”€â”€ visualizations/
    â”œâ”€â”€ prisma_flow.png             âŒ Mostra 9356 identificados (INCORRETO)
    â”œâ”€â”€ selection_funnel.png        âŒ Mostra 9356 no topo (INCORRETO)
    â”œâ”€â”€ papers_by_year.png          âœ… Baseado em 6.516 (correto)
    â”œâ”€â”€ techniques_distribution.png âœ… Correto
    â”œâ”€â”€ database_coverage.png       âœ… Correto
    â””â”€â”€ relevance_distribution.png  âœ… Correto
```

### âŒ Problemas nos Reports HTML

**Arquivo**: `research/exports/analysis/reports/summary_report.html`

**Linhas problemÃ¡ticas**:

```html
<!-- Linha 56 -->
<h3>9356</h3>
<p>Total de Papers</p>

<!-- Linha 81 - Tabela PRISMA -->
<td>ğŸ“š IdentificaÃ§Ã£o</td>
<td style="text-align: right;">9356</td>

<!-- Linha 84 -->
<td>ğŸ” Triagem (aprovados)</td>
<td style="text-align: right;">6516</td>
```

**CÃ¡lculo ImplÃ­cito (ERRADO)**:
- IdentificaÃ§Ã£o: 9.356
- Duplicatas removidas: 2.840 (nÃ£o documentado, mas implÃ­cito por 9356 - 6516)
- Triagem: 6.516

**CÃ¡lculo Correto**:
- IdentificaÃ§Ã£o: **6.516** (jÃ¡ deduplicados no banco)
- Duplicatas: **0** (deduplicaÃ§Ã£o feita antes de inserir no banco)
- Triagem: 6.516

---

## ğŸ“ DocumentaÃ§Ã£o Markdown

### âœ… METODOLOGIA.md (Correto)

```markdown
**Total de registros identificados**: 6.516
- Crossref: ~43,8%
- OpenAlex: ~27,0%
- Semantic Scholar: ~27,3%
- CORE: ~2,0%

**Triagem (Screening)**: 4.665 â†’ 28,4% excluÃ­dos
**Elegibilidade**: 1.835 â†’ 99,1% excluÃ­dos
**IncluÃ­dos (final)**: 16 estudos (~0,25%)
```

### âœ… RESUMO.md (Correto)

```markdown
| Etapa | Quantidade |
|-------|-----------|
| IdentificaÃ§Ã£o | 6.516 |
| Triagem | 4.665 |
| Elegibilidade | 1.835 |
| IncluÃ­dos | 16 |
```

### âœ… CONCLUSOES.md (Atualizado 16/11)

Atualizado de `12.533/43` â†’ `6.516/16` âœ…

### âœ… CRONOGRAMA.md (Atualizado 16/11)

Atualizado com mÃ©tricas canÃ´nicas âœ…

---

## ğŸ› AnÃ¡lise de Causa Raiz

### Problema 1: Valor 9.356 nos RelatÃ³rios

**Arquivo**: `research/src/exports/excel.py` (linha 268-277)

```python
def _compute_prisma_stats_from_df(df: pd.DataFrame) -> dict:
    stats = {}
    stats['identification'] = len(df)  # âœ… Correto: conta linhas do DataFrame
    if 'selection_stage' in df.columns:
        stats['screening'] = int(len(df))
        stats['eligibility'] = int(df['selection_stage'].isin(['eligibility', 'included']).sum())
        stats['included'] = int((df['selection_stage'] == 'included').sum())
        stats['screening_excluded'] = int((df['selection_stage'] == 'screening').sum())
        stats['eligibility_excluded'] = int((df['selection_stage'] == 'eligibility').sum())
    return stats
```

**Mas entÃ£o** (linha 323-324):

```python
# Use PRISMA stats from pipeline (already computed from deduplicated data)
local_stats = dict(stats) if stats else _compute_prisma_stats_from_df(df)
```

**Raiz do problema**: `stats` passado externamente contÃ©m valores **INCORRETOS** de `dedup_stats.initial_count`

**Arquivo**: `research/src/processing/selection.py` (linha 39-45)

```python
def _load_dedup_stats_from_df(self, df: pd.DataFrame) -> None:
    """If the dataframe carries dedup_stats in attrs, load them into selector stats."""
    try:
        dedup = getattr(df, 'attrs', {}).get('dedup_stats') if df is not None else None
        if dedup:
            self.stats['identification'] = int(dedup.get('initial_count', 0))  # âŒ PROBLEMA!
            self.stats['duplicates_removed'] = int(dedup.get('total_removed', 0))
    except Exception:
        logger.debug("No dedup_stats available on DataFrame.attrs")
```

**ExplicaÃ§Ã£o**:
- `dedup_stats.initial_count` = 9.356 (total **ANTES** da deduplicaÃ§Ã£o durante a coleta)
- `dedup_stats.total_removed` = 2.840 (duplicatas removidas **ANTES** de inserir no banco)
- Mas o **banco SQLite jÃ¡ contÃ©m apenas 6.516 papers Ãºnicos**
- Usar `initial_count` nos relatÃ³rios cria discrepÃ¢ncia porque os dados jÃ¡ foram deduplicados

### Problema 2: PRISMA Flow Diagram

**Arquivo**: `research/src/analysis/visualizations.py` (linha 97-111)

```python
identification = int(stats.get('identification', 0))
duplicates_removed = int(stats.get('duplicates_removed', 0))
screening_total = int(stats.get('screening', 0))

logger.info(
    f"PRISMA stats used -> ident={identification}, dup_removed={duplicates_removed}, "
    f"screening={screening_total}, eligibility={eligibility_total}, included={included}"
)
```

**Logs observados** (16/11 22:30):

```
PRISMA stats used -> ident=9356, dup_removed=2594, screening=6516, 
eligibility=1851, included=16, screening_excl=4665, eligibility_excl=1835
```

**Problema**: `ident=9356` estÃ¡ ERRADO! Deveria ser `ident=6516` (valor do banco)

---

## ğŸ¯ Valores Corretos vs Incorretos

### Tabela Comparativa

| MÃ©trica | Valor Correto (Banco) | Valor Incorreto (HTML) | DiscrepÃ¢ncia |
|---------|----------------------|------------------------|--------------|
| **Identificados** | **6.516** | 9.356 | +2.840 |
| Duplicatas removidas | 0 (jÃ¡ dedup) | 2.594 | +2.594 |
| Triagem (total) | 6.516 | 6.516 | âœ… OK |
| Triagem (exclusÃµes) | 4.665 | 4.665 | âœ… OK |
| Elegibilidade (total) | 1.835 + 16 = 1.851 | 1.851 | âœ… OK |
| Elegibilidade (exclusÃµes) | 1.835 | 1.835 | âœ… OK |
| **IncluÃ­dos** | **16** | **16** | âœ… OK |

### Fluxo PRISMA Correto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  IDENTIFICAÃ‡ÃƒO: 6.516 registros Ãºnicos  â”‚
â”‚  (DeduplicaÃ§Ã£o realizada ANTES do DB)   â”‚
â”‚                                         â”‚
â”‚  â”œâ”€ Crossref: 2.815 (43,2%)            â”‚
â”‚  â”œâ”€ OpenAlex: 1.793 (27,5%)            â”‚
â”‚  â”œâ”€ Semantic Scholar: 1.782 (27,3%)    â”‚
â”‚  â””â”€ CORE: 126 (1,9%)                   â”‚
â”‚                                         â”‚
â”‚  PerÃ­odo: 2017-2025 (9 anos)           â”‚
â”‚  Queries: 108 bilÃ­ngues                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (Screening automÃ¡tico)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRIAGEM: 6.516 registros avaliados     â”‚
â”‚  âŒ ExcluÃ­dos: 4.665 (71,6%)            â”‚
â”‚     â”œâ”€ abstract_too_short: 2.720       â”‚
â”‚     â”œâ”€ inclusion_criteria: 1.010       â”‚
â”‚     â”œâ”€ no_methodology: 870             â”‚
â”‚     â””â”€ outros: 65                      â”‚
â”‚  âœ… Aprovados: 1.851 (28,4%)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (Score â‰¥ 4.0)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ELEGIBILIDADE: 1.851 registros         â”‚
â”‚  âŒ ExcluÃ­dos: 1.835 (99,1%)            â”‚
â”‚     â””â”€ low_relevance_score: 1.835      â”‚
â”‚  âœ… Aprovados: 16 (0,9%)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (CritÃ©rios finais)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INCLUÃDOS: 16 estudos (0,25%)          â”‚
â”‚                                         â”‚
â”‚  âœ… Score mÃ©dio: 4.20                   â”‚
â”‚  âœ… Score range: 4.0 - 4.5              â”‚
â”‚  âœ… Anos: 2017-2025                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ AÃ§Ãµes Corretivas NecessÃ¡rias

### 1. CorreÃ§Ã£o de CÃ³digo (Alta Prioridade)

**Arquivo**: `research/src/exports/excel.py`

**Problema**: FunÃ§Ã£o `_compute_prisma_stats_from_df()` ignora que `stats` pode conter valores prÃ©-dedup

**SoluÃ§Ã£o**: Sempre recalcular `identification` a partir do DataFrame quando nÃ£o hÃ¡ `stats['duplicates_removed']`:

```python
def _compute_prisma_stats_from_df(df: pd.DataFrame) -> dict:
    stats = {}
    # SEMPRE usar len(df) para identification (dados jÃ¡ dedup no banco)
    stats['identification'] = len(df)
    stats['duplicates_removed'] = 0  # JÃ¡ foi feito antes do DB
    
    if 'selection_stage' in df.columns:
        stats['screening'] = int(len(df))
        stats['eligibility'] = int(df['selection_stage'].isin(['eligibility', 'included']).sum())
        stats['included'] = int((df['selection_stage'] == 'included').sum())
        stats['screening_excluded'] = int((df['selection_stage'] == 'screening').sum())
        stats['eligibility_excluded'] = int((df['selection_stage'] == 'eligibility').sum())
    return stats
```

**Arquivo**: `research/src/processing/selection.py`

**SoluÃ§Ã£o**: NÃ£o carregar `dedup_stats.initial_count` para `self.stats['identification']` OU documentar claramente que Ã© prÃ©-dedup:

```python
def _load_dedup_stats_from_df(self, df: pd.DataFrame) -> None:
    """Load dedup stats from DataFrame attrs (historical, pre-database values)."""
    try:
        dedup = getattr(df, 'attrs', {}).get('dedup_stats') if df is not None else None
        if dedup:
            # NÃƒO usar initial_count - dados no DF jÃ¡ estÃ£o deduplicados
            # self.stats['identification'] = len(df)  # Usar tamanho real do DF
            self.stats['duplicates_removed'] = int(dedup.get('total_removed', 0))
            self.stats['_historical_initial_count'] = int(dedup.get('initial_count', 0))  # Apenas para log
    except Exception:
        logger.debug("No dedup_stats available on DataFrame.attrs")
```

### 2. Regenerar Exports (Alta Prioridade)

```bash
cd /c/dev/ccw
python -m research.src.cli export -o research/exports/analysis/
```

**Arquivos afetados**:
- âŒ `summary_report.html` (linha 56: 9356 â†’ 6516)
- âŒ `prisma_flow.png` (box "IdentificaÃ§Ã£o": 9356 â†’ 6516)
- âŒ `selection_funnel.png` (topo do funil: 9356 â†’ 6516)

### 3. Atualizar DocumentaÃ§Ã£o (MÃ©dia Prioridade)

**Arquivos corretos (nÃ£o precisam atualizaÃ§Ã£o)**:
- âœ… METODOLOGIA.md
- âœ… RESUMO.md
- âœ… RESULTADOS_PRELIMINARES.md
- âœ… CONCLUSOES.md
- âœ… CRONOGRAMA.md

**Arquivos que precisam revisÃ£o**:
- âš ï¸ **README_DOCS.md**: Remover referÃªncias a `deep_analysis/` (excluÃ­do pelo usuÃ¡rio)
- âš ï¸ **ANALISE_ESTRUTURA_DOCS.md**: Atualizar seÃ§Ã£o de exports com warnings sobre discrepÃ¢ncias

### 4. ValidaÃ§Ã£o Final (Alta Prioridade)

```bash
# Confirmar valor canÃ´nico
sqlite3 research/systematic_review.sqlite "SELECT COUNT(*) FROM papers"
# Esperado: 6516

# Verificar exports regenerados
grep -r "9356" research/exports/analysis/reports/
# Esperado: 0 matches

# Validar HTML
python -c "
from bs4 import BeautifulSoup
with open('research/exports/analysis/reports/summary_report.html') as f:
    soup = BeautifulSoup(f, 'html.parser')
    stat_cards = soup.find_all('div', class_='stat-card')
    total = stat_cards[0].find('h3').text
    print(f'Total no HTML: {total}')
    assert total == '6516', f'Esperado 6516, encontrado {total}'
"
```

---

## ğŸ“Š Impacto da InconsistÃªncia

### Documentos Afetados

| Documento | Status Antes | Status Atual | AÃ§Ã£o |
|-----------|--------------|--------------|------|
| `summary_report.html` | âŒ 9356 | â³ Pendente | Regenerar export |
| `prisma_flow.png` | âŒ 9356 | â³ Pendente | Regenerar export |
| `selection_funnel.png` | âŒ 9356 | â³ Pendente | Regenerar export |
| METODOLOGIA.md | âœ… 6516 | âœ… Correto | Nenhuma |
| RESUMO.md | âœ… 6516 | âœ… Correto | Nenhuma |
| CONCLUSOES.md | âœ… 6516 | âœ… Correto | Nenhuma |
| README_DOCS.md | âœ… 6516 | âš ï¸ Refs deep_analysis/ | Limpar refs |
| ANALISE_ESTRUTURA_DOCS.md | âœ… 6516 | âš ï¸ Refs deep_analysis/ | Limpar refs |

### Impacto AcadÃªmico

**Gravidade**: ğŸ”´ **ALTA** - InconsistÃªncia em mÃ©tricas PRISMA compromete reprodutibilidade

**Riscos**:
1. **RevisÃ£o por pares**: Avaliadores questionarÃ£o discrepÃ¢ncia entre nÃºmeros documentados
2. **Reprodutibilidade**: ImpossÃ­vel replicar anÃ¡lise com valores conflitantes
3. **Credibilidade**: InconsistÃªncias indicam falta de rigor metodolÃ³gico
4. **ComparaÃ§Ãµes**: Outros pesquisadores nÃ£o conseguirÃ£o comparar resultados

**MitigaÃ§Ã£o**:
- âœ… Banco de dados SQLite Ã© fonte canÃ´nica confiÃ¡vel
- âœ… DocumentaÃ§Ã£o Markdown (METODOLOGIA, RESUMO) estÃ¡ correta
- â³ Exports HTML precisam regeneraÃ§Ã£o URGENTE

---

## âœ… Checklist de CorreÃ§Ã£o

### CÃ³digo (Prioridade: ğŸ”´ Alta)

- [ ] Corrigir `research/src/exports/excel.py::_compute_prisma_stats_from_df()`
- [ ] Corrigir `research/src/processing/selection.py::_load_dedup_stats_from_df()`
- [ ] Adicionar testes unitÃ¡rios para validaÃ§Ã£o de mÃ©tricas PRISMA
- [ ] Validar que `len(df)` sempre prevalece sobre `dedup_stats.initial_count`

### Exports (Prioridade: ğŸ”´ Alta)

- [ ] Executar `python -m research.src.cli export -o research/exports/analysis/`
- [ ] Validar `summary_report.html` mostra 6516 (nÃ£o 9356)
- [ ] Validar `prisma_flow.png` mostra 6516 no box "IdentificaÃ§Ã£o"
- [ ] Validar `selection_funnel.png` mostra 6516 no topo do funil

### DocumentaÃ§Ã£o (Prioridade: ğŸŸ¡ MÃ©dia)

- [ ] Remover referÃªncias a `deep_analysis/` em README_DOCS.md
- [ ] Remover referÃªncias a `deep_analysis/` em ANALISE_ESTRUTURA_DOCS.md
- [ ] Adicionar warning sobre versÃµes antigas de exports
- [ ] Documentar processo de auditoria para futuras validaÃ§Ãµes

### ValidaÃ§Ã£o (Prioridade: ğŸ”´ Alta)

- [ ] Confirmar banco SQLite tem 6516 papers (fonte canÃ´nica)
- [ ] Grep por "9356" em todos os arquivos (deve retornar 0 matches em docs ativos)
- [ ] Validar todos os 16 papers incluÃ­dos tÃªm `relevance_score >= 4.0`
- [ ] Confirmar 0 duplicatas marcadas no banco
- [ ] Executar `pytest tests/` para validar integridade do pipeline

---

## ğŸ“Œ Notas Adicionais

### Sobre Duplicatas

**ObservaÃ§Ã£o importante**: O valor "2.594 duplicatas removidas" nos logs refere-se a:
- Duplicatas identificadas **DURANTE A COLETA** (fase de ingestÃ£o)
- **NÃƒO** sÃ£o papers presentes no banco SQLite
- DeduplicaÃ§Ã£o ocorre **ANTES** de inserir no banco
- Banco contÃ©m **APENAS** os 6.516 papers Ãºnicos

**ImplicaÃ§Ã£o**: Reportar "9.356 identificados - 2.594 duplicatas = 6.762" Ã© **INCORRETO** porque:
1. O banco **JÃ** contÃ©m dados deduplicados (6.516)
2. NÃ£o hÃ¡ registro de duplicatas para apresentar no PRISMA (foram descartadas antes do DB)
3. PRISMA flow deve mostrar: "**6.516 identificados** (apÃ³s deduplicaÃ§Ã£o automÃ¡tica durante coleta)"

### RecomendaÃ§Ã£o de Nomenclatura

**Atual** (confuso):
```
IdentificaÃ§Ã£o: 9.356
Duplicatas removidas: 2.594
Triagem: 6.516
```

**Proposto** (claro):
```
Registros coletados: 9.356
Duplicatas removidas (automÃ¡tico): 2.594
IdentificaÃ§Ã£o (Ãºnicos): 6.516
Triagem: 6.516
```

OU simplesmente:

```
IdentificaÃ§Ã£o: 6.516 (registros Ãºnicos)
Triagem: 6.516
Elegibilidade: 1.851
IncluÃ­dos: 16
```

### PrincÃ­pio KISS (Keep It Simple, Stupid)

Conforme solicitado pelo usuÃ¡rio:
- âœ… **Fonte Ãºnica de verdade**: SQLite database
- âœ… **Sem redundÃ¢ncia**: NÃ£o reportar valores prÃ©-dedup em produÃ§Ã£o
- âœ… **Clareza**: NÃºmeros devem refletir estado atual do banco
- âŒ **Evitar**: CÃ¡lculos derivados (9356 - 2594) que confundem leitores

---

## ğŸ¯ Resumo para TCC/PTC

**Usar SEMPRE estes valores**:

```yaml
identificacao: 6516
triagem_excluidos: 4665
triagem_aprovados: 1851
elegibilidade_excluidos: 1835
elegibilidade_aprovados: 16
incluidos_final: 16

taxa_inclusao: 0.25%  # (16/6516)
taxa_exclusao_triagem: 71.6%  # (4665/6516)
taxa_exclusao_elegibilidade: 99.1%  # (1835/1851)

score_medio_incluidos: 4.20
score_minimo: 4.0
score_maximo: 4.5

bases_dados: 4
queries_total: 108
periodo: 2017-2025
anos_cobertos: 9
```

---

**Ãšltima AtualizaÃ§Ã£o**: 16/11/2025 22:35  
**Auditado por**: Sistema automatizado + revisÃ£o manual  
**PrÃ³xima RevisÃ£o**: ApÃ³s correÃ§Ã£o de cÃ³digo e regeneraÃ§Ã£o de exports
